<!DOCTYPE html><html class=no-js lang=zh> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content=awslasasd的笔记本 name=description><meta content=awslasasd name=author><link href=https://awslasasd.github.io/Class/class_source/renji/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%87%AA%E5%8A%A8%E8%B5%B0%E8%BF%B7%E5%AE%AB/ rel=canonical><link href=../../../../assets/images/favicon.png rel=icon><meta content="mkdocs-1.6.0, mkdocs-material-9.5.28" name=generator><title>机器人自动走迷宫 - awslasasd's Notebook</title><link href=../../../../assets/stylesheets/main.6543a935.min.css rel=stylesheet><link href=../../../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13.274 9.537v-.001l-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074ZM4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75Z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.484 4.484 0 0 1-.563-1.191 3.835 3.835 0 0 1-.05-2.063 4.647 4.647 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .748.748 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.425 2.425 0 0 1-.507-.441 3.075 3.075 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19a.884.884 0 0 1 .01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.737 3.737 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353V.75Z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.756 2.756 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6.24 6.24 0 0 0-.26.16.952.952 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661.103-.067.207-.132.313-.195l.007-.004c.1-.061.182-.11.258-.161a.969.969 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.612.612 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1.01 1.01 0 0 0-.34.398ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343h-.001a8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746Zm1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275ZM6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L6.94 8 4.97 6.03a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018Z"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.249 1.249 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429Zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006a.036.036 0 0 0-.004-.009l-.006-.006-.008-.001c-.003 0-.006.002-.009.004Z"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.488 3.488 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A4.997 4.997 0 0 1 8 16a4.997 4.997 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5.036 5.036 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.677 1.677 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06Zm.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.172.172 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173Z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.746.746 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5Zm4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0Z"/></svg>');}</style><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Noto Serif SC";--md-code-font:"JetBrains Mono"}</style><link href=../../../../css/heti.css rel=stylesheet><link href=../../../../style/css/custom.css rel=stylesheet><link href=../../../../style/css/counter.css rel=stylesheet><link href=../../../../style/css/toc.css rel=stylesheet><link href=../../../../style/css/flink.css rel=stylesheet><link href=https://cdn.tonycrane.cc/jbmono/jetbrainsmono.css rel=stylesheet><link href=https://cdn.tonycrane.cc/lxgw/lxgwscreen.css rel=stylesheet><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent=red data-md-color-primary=white data-md-color-scheme=default dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#_1> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav aria-label=页眉 class="md-header__inner md-grid"> <a aria-label="awslasasd's Notebook" class="md-header__button md-logo" data-md-component=logo href=../../../.. title="awslasasd's Notebook"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> awslasasd's Notebook </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 机器人自动走迷宫 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=red data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary=white data-md-color-scheme=default id=__palette_0 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"></path></svg> </label> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary=indigo data-md-color-scheme=slate id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_0 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"></path></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=搜索 autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=搜索 required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label=查找 class=md-search__options> <a aria-label=分享 class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=分享> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"></path></svg> </a> <button aria-label=清空当前内容 class="md-search__icon md-icon" tabindex=-1 title=清空当前内容 type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix tabindex=0> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/awslasasd/awslasasd.github.io title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class=md-source__repository> awslasasd/Notes </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav aria-label=标签 class=md-tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a class=md-tabs__link href=../../../..> Home </a> </li> <li class=md-tabs__item> <a href=../../../%E7%94%B5%E6%B0%94%E6%8E%A7%E5%88%B6%E6%8A%80%E6%9C%AF/ class=md-tabs__link> Class </a> </li> <li class=md-tabs__item> <a href=../../../../Robotics/%E7%A9%BA%E4%B8%AD%E6%9C%BA%E5%99%A8%E4%BA%BA/ class=md-tabs__link> Robotics </a> </li> <li class=md-tabs__item> <a href=../../../../Tools/Git/ class=md-tabs__link> Tools </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航栏 class="md-nav md-nav--primary md-nav--lifted" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="awslasasd's Notebook" class="md-nav__button md-logo" data-md-component=logo href=../../../.. title="awslasasd's Notebook"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> awslasasd's Notebook </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/awslasasd/awslasasd.github.io title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class=md-source__repository> awslasasd/Notes </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../../../..> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_2 type=checkbox> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Class </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_2_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Class </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%94%B5%E6%B0%94%E6%8E%A7%E5%88%B6%E6%8A%80%E6%9C%AF/ class=md-nav__link> <span class=md-ellipsis> 电气控制技术 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E6%99%BA%E8%83%BD%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87%E5%BC%80%E5%8F%91/ class=md-nav__link> <span class=md-ellipsis> 智能电子设备开发 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E7%8E%B0%E4%BB%A3%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/ class=md-nav__link> <span class=md-ellipsis> 现代控制原理 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ class=md-nav__link> <span class=md-ellipsis> 人工智能与机器学习 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E6%99%BA%E8%83%BD%E6%8E%A7%E5%88%B6%E6%8A%80%E6%9C%AF/ class=md-nav__link> <span class=md-ellipsis> 智能控制技术 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E4%BC%A0%E6%84%9F%E4%B8%8E%E6%A3%80%E6%B5%8B/ class=md-nav__link> <span class=md-ellipsis> 传感与检测 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E6%AF%9B%E6%A6%82/ class=md-nav__link> <span class=md-ellipsis> 毛概 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E8%BF%90%E5%8A%A8%E6%8E%A7%E5%88%B6/ class=md-nav__link> <span class=md-ellipsis> 运动控制 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AF%BC%E8%AE%BA/ class=md-nav__link> <span class=md-ellipsis> 信息安全导论 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Robotics </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Robotics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../Robotics/%E7%A9%BA%E4%B8%AD%E6%9C%BA%E5%99%A8%E4%BA%BA/ class=md-nav__link> <span class=md-ellipsis> 空中机器人 </span> </a> </li> <li class=md-nav__item> <a href=../../../../Robotics/%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AB%9E%E8%B5%9B%E5%AE%9E%E8%AE%AD/ class=md-nav__link> <span class=md-ellipsis> 自动化竞赛实训 </span> </a> </li> <li class=md-nav__item> <a href=../../../../Robotics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ class=md-nav__link> <span class=md-ellipsis> 机器学习 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_4 type=checkbox> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Tools </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_4_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../Tools/Git/ class=md-nav__link> <span class=md-ellipsis> Git </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/Createsite/ class=md-nav__link> <span class=md-ellipsis> Createsite </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/latex/ class=md-nav__link> <span class=md-ellipsis> Latex </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/Juypter/ class=md-nav__link> <span class=md-ellipsis> Juypter </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/AI/ class=md-nav__link> <span class=md-ellipsis> AI </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/%E5%8F%91%E5%B1%95%E5%AF%B9%E8%B1%A1%E8%80%83%E8%AF%95/ class=md-nav__link> <span class=md-ellipsis> 发展对象 </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/OneDrive/ class=md-nav__link> <span class=md-ellipsis> OneDrive </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_4_8 type=checkbox> <label class=md-nav__link for=__nav_4_8 id=__nav_4_8_label tabindex=0> <span class=md-ellipsis> Linux </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_4_8_label class=md-nav data-md-level=2> <label class=md-nav__title for=__nav_4_8> <span class="md-nav__icon md-icon"></span> Linux </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../Tools/Linux/linux/ class=md-nav__link> <span class=md-ellipsis> 双系统更改开机顺序 </span> </a> </li> <li class=md-nav__item> <a href=../../../../Tools/Linux/ssh/ class=md-nav__link> <span class=md-ellipsis> SSH </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=目录 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#_2> <span class=md-ellipsis> 实验目的 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_3> <span class=md-ellipsis> 实验介绍 </span> </a> <nav aria-label=实验介绍 class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#_4> <span class=md-ellipsis> 实验内容 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_5> <span class=md-ellipsis> 实验要求 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_6> <span class=md-ellipsis> 实验环境 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_7> <span class=md-ellipsis> 注意事项 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_8> <span class=md-ellipsis> 参考资料 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#_9> <span class=md-ellipsis> 实验内容 </span> </a> <nav aria-label=实验内容 class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#mzae> <span class=md-ellipsis> Mzae类 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_12> <span class=md-ellipsis> 强化学习算法 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_14> <span class=md-ellipsis> 实现目标 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_15> <span class=md-ellipsis> 实验代码 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_16> <span class=md-ellipsis> 实验结果 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_17> <span class=md-ellipsis> 对比分析 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_18> <span class=md-ellipsis> 结论 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_19> <span class=md-ellipsis> 改进方向 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#_20> <span class=md-ellipsis> 附录 </span> </a> <nav aria-label=附录 class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#mainpy> <span class=md-ellipsis> Main.py </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>机器人自动走迷宫<a class=headerlink href=#_1 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h1> <div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;"> <p><span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8V2m6.78 1a.69.69 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38-2.5-2.5Z"></path></svg></span> 约<span class=heti-skip><span class=heti-spacing> </span>2965<span class=heti-spacing> </span></span>个字 <span class=twemoji><svg viewbox="0 0 640 512" xmlns=http://www.w3.org/2000/svg><path d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6zm80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3l89.3 89.4-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3z"></path></svg></span> <span>257<span class=heti-spacing> </span></span>行代码 <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3L12.5 13Z"></path></svg></span> 预计阅读时间<span class=heti-skip><span class=heti-spacing> </span>15<span class=heti-spacing> </span></span>分钟</p> </div> <h2 id=_2>实验目的<a class=headerlink href=#_2 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h2> <ol> <li> <p>掌握迷宫环境下的路径规划算法，包括深度优先搜索（DFS）算法的实现和应用。</p> </li> <li> <p>探索强化学习在复杂环境中的应用，尤其是利用深度强化学习（DQN）算法解决机器人路径规划问题。</p> </li> <li> <p>通过对比传统算法和强化学习方法，理解不同算法的优缺点。</p> </li> <li> <p>学习基于<span class=heti-skip><span class=heti-spacing> </span>PyTorch<span class=heti-spacing> </span></span>深度学习框架的机器人训练与路径规划实现。</p> </li> </ol> <h2 id=_3>实验介绍<a class=headerlink href=#_3 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h2> <h3 id=_4>实验内容<a class=headerlink href=#_4 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <p>在本实验中，要求分别使用基础搜索算法和<span class=heti-skip><span class=heti-spacing> </span>Deep QLearning<span class=heti-spacing> </span></span>算法，完成机器人自动走迷宫。</p> <p><img src=https://imgbed.momodel.cn/20200914145238.png width=40%></p> <p>如上图所示，左上角的红色椭圆既是起点也是机器人的初始位置，右下角的绿色方块是出口。 <br> 游戏规则为：从起点开始，通过错综复杂的迷宫，到达目标点(出口)。</p> <ul> <li>在任一位置可执行动作包括：向上走 <code>'u'</code>、向右走 <code>'r'</code>、向下走 <code>'d'</code>、向左走 <code>'l'</code>。</li> <li> <p>执行不同的动作后，根据不同的情况会获得不同的奖励，具体而言，有以下几种情况。</p> <ul> <li>撞墙</li> <li>走到出口</li> <li>其余情况</li> </ul> </li> <li> <p>需要您分别实现<strong>基于基础搜索算法</strong>和 <strong><span>Deep QLearning<span class=heti-spacing> </span></span>算法</strong>的机器人，使机器人自动走到迷宫的出口。</p> </li> </ul> <h3 id=_5>实验要求<a class=headerlink href=#_5 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <ul> <li>使用<span class=heti-skip><span class=heti-spacing> </span>Python<span class=heti-spacing> </span></span>语言。</li> <li>使用基础搜索算法完成机器人走迷宫。</li> <li>使用<span class=heti-skip><span class=heti-spacing> </span>Deep QLearning<span class=heti-spacing> </span></span>算法完成机器人走迷宫。</li> <li>算法部分需要自己实现，不能使用现成的包、工具或者接口。</li> </ul> <h3 id=_6>实验环境<a class=headerlink href=#_6 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <p>可以使用<span class=heti-skip><span class=heti-spacing> </span>Python<span class=heti-spacing> </span></span>实现基础算法的实现， 使用<span><span class=heti-spacing> </span>Keras</span>、<span>PyTorch<span class=heti-spacing> </span></span>等框架实现<span class=heti-skip><span class=heti-spacing> </span>Deep QLearning<span class=heti-spacing> </span></span>算法。</p> <h3 id=_7>注意事项<a class=headerlink href=#_7 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <ul> <li><span>Python<span class=heti-spacing> </span></span>与<span class=heti-skip><span class=heti-spacing> </span>Python Package<span class=heti-spacing> </span></span>的使用方式，可在右侧 <code>API文档</code> 中查阅。</li> <li>当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动<span class=heti-skip><span class=heti-spacing> </span>Kernel<span class=heti-spacing> </span></span>解决（左上角『Kernel』-『Restart Kernel<heti-adjacent class=heti-adjacent-half>』</heti-adjacent><heti-adjacent class=heti-adjacent-half>）</heti-adjacent>。</li> </ul> <h3 id=_8>参考资料<a class=headerlink href=#_8 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <ul> <li>强化学习入门<span><span class=heti-spacing> </span>MDP</span>：<a href=https://zhuanlan.zhihu.com/p/25498081>https://zhuanlan.zhihu.com/p/25498081</a></li> <li><span>QLearning<span class=heti-spacing> </span></span>示例：<a href=http://mnemstudio.org/path-finding-q-learning-tutorial.htm>http://mnemstudio.org/path-finding-q-learning-tutorial.htm</a></li> <li><span>QLearning<span class=heti-spacing> </span></span>知乎解释：<a href=https://www.zhihu.com/question/26408259>https://www.zhihu.com/question/26408259</a></li> <li><span>DeepQLearning<span class=heti-spacing> </span></span>论文：<a href=https://files.momodel.cn/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf>https://files.momodel.cn/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf</a></li> </ul> <h2 id=_9>实验内容<a class=headerlink href=#_9 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h2> <h3 id=mzae><span>Mzae<span class=heti-spacing> </span></span>类<a class=headerlink href=#mzae title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <h4 id=_10>创建迷宫<a class=headerlink href=#_10 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h4> <p>通过迷宫类<span class=heti-skip><span class=heti-spacing> </span>Maze<span class=heti-spacing> </span></span>可以随机创建一个迷宫。</p> <ol> <li>使用<span class=heti-skip><span class=heti-spacing> </span>Maze(maze_size=size)<span class=heti-spacing> </span></span>来随机生成一个<span class=heti-skip><span class=heti-spacing> </span>size * size<span class=heti-spacing> </span></span>大小的迷宫。</li> <li>使用<span class=heti-skip><span class=heti-spacing> </span>print()<span class=heti-spacing> </span></span>函数可以输出迷宫的<span class=heti-skip><span class=heti-spacing> </span>size<span class=heti-spacing> </span></span>以及画出迷宫图</li> <li>红色的圆是机器人初始位置</li> <li>绿色的方块是迷宫的出口位置</li> </ol> <h4 id=_11>重要的成员方法<a class=headerlink href=#_11 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h4> <p>在迷宫中已经初始化一个机器人，你要编写的算法实现在给定条件下控制机器人移动至目标点。</p> <p><span>Maze<span class=heti-spacing> </span></span>类中重要的成员方法如下：</p> <ol> <li>sense_robot() ：获取机器人在迷宫中目前的位置。</li> </ol> <blockquote> <p>return：机器人在迷宫中目前的位置。</p> </blockquote> <ol> <li>move_robot(direction) ：根据输入方向移动默认机器人，若方向不合法则返回错误信息。</li> </ol> <blockquote> <p>direction：移动方向<span class=heti-skip><span class=heti-spacing> </span>,<span class=heti-spacing> </span></span>如<span class=heti-skip><span class=heti-spacing> </span>:"u",<span class=heti-spacing> </span></span>合法值为： ['u', 'r', 'd', 'l']</p> <p>return：执行动作的奖励值</p> </blockquote> <ol> <li>can_move_actions(position)：获取当前机器人可以移动的方向</li> </ol> <blockquote> <p>position：迷宫中任一处的坐标点 </p> <p>return：该点可执行的动作，如：['u','r','d']</p> </blockquote> <ol> <li>is_hit_wall(self, location, direction)：判断该移动方向是否撞墙</li> </ol> <blockquote> <p>location, direction：当前位置和要移动的方向，如<span><span class=heti-spacing> </span>(0,0) , "u"</span></p> <p>return：<span>True(<span class=heti-spacing> </span></span>撞墙<span class=heti-skip><span class=heti-spacing> </span>) / False(<span class=heti-spacing> </span></span>不撞墙<span><span class=heti-spacing> </span>)</span></p> </blockquote> <ol> <li>draw_maze()：画出当前的迷宫</li> </ol> <h3 id=_12>强化学习算法<a class=headerlink href=#_12 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <p>强化学习作为机器学习算法的一种，其模式也是让智能体在“训练”中学到“经验”，以实现给定的任务。 <br> 但不同于监督学习与非监督学习，在强化学习的框架中，我们更侧重通过智能体与环境的<strong>交互</strong>来学习。 <br> 通常在监督学习和非监督学习任务中，智能体往往需要通过给定的训练集，辅之以既定的训练目标（如最小化损失函数），通过给定的学习算法来实现这一目标。 <br> 然而在强化学习中，智能体则是通过其与环境交互得到的奖励进行学习。 <br> 这个环境可以是虚拟的（如虚拟的迷宫），也可以是真实的（自动驾驶汽车在真实道路上收集数据）。</p> <p>在强化学习中有五个核心组成部分，它们分别是：<strong>环境（Environment）</strong>、<strong>智能体（Agent）</strong>、<strong>状态（State）</strong>、<strong>动作（Action）</strong>和<strong>奖励（Reward）</strong>。</p> <p>在某一时间节点<span><span class=heti-spacing> </span><span class=arithmatex>\(t\)</span></span>：</p> <ul> <li>智能体在从环境中感知其所处的状态<span><span class=heti-spacing> </span><span class=arithmatex>\(s_t\)</span></span></li> <li>智能体根据某些准则选择动作<span><span class=heti-spacing> </span><span class=arithmatex>\(a_t\)</span></span></li> <li>环境根据智能体选择的动作，向智能体反馈奖励<span><span class=heti-spacing> </span><span class=arithmatex>\(r_{t+1}\)</span></span></li> </ul> <p>通过合理的学习算法，智能体将在这样的问题设置下，成功学到一个在状态<span class=heti-skip><span class=heti-spacing> </span><span class=arithmatex>\(s_t\)</span><span class=heti-spacing> </span></span>选择动作<span class=heti-skip><span class=heti-spacing> </span><span class=arithmatex>\(a_t\)</span><span class=heti-spacing> </span></span>的策略<span><span class=heti-spacing> </span><span class=arithmatex>\(\pi (s_t) = a_t\)</span></span>。</p> <p><img width=400px/ src=https://imgbed.momodel.cn/20200914153419.png></p> <h4 id=qlearning><span>QLearning<span class=heti-spacing> </span></span>算法<a class=headerlink href=#qlearning title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h4> <p><span>Q-Learning<span class=heti-spacing> </span></span>是一个值迭代（Value Iteration）算法。 <br> 与策略迭代（Policy Iteration）算法不同，值迭代算法会计算每个”状态“或是”状态-动作“的值（Value）或是效用（Utility），然后在执行动作的时候，会设法最大化这个值。 <br> 因此，对每个状态值的准确估计，是值迭代算法的核心。 <br> 通常会考虑<strong>最大化动作的长期奖励</strong>，即不仅考虑当前动作带来的奖励，还会考虑动作长远的奖励。</p> <h5 id=q><span>Q<span class=heti-spacing> </span></span>值的计算与迭代<a class=headerlink href=#q title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h5> <p><span>Q-learning<span class=heti-spacing> </span></span>算法将状态（state）和动作（action）构建成一张<span class=heti-skip><span class=heti-spacing> </span>Q_table<span class=heti-spacing> </span></span>表来存储<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值，<span>Q<span class=heti-spacing> </span></span>表的行代表状态（state<heti-adjacent class=heti-adjacent-half>）</heti-adjacent>，列代表动作（action<heti-adjacent class=heti-adjacent-half>）</heti-adjacent>：</p> <p><img width=400px/ src=https://imgbed.momodel.cn/20200914161241.png></p> <p>在<span class=heti-skip><span class=heti-spacing> </span>Q-Learning<span class=heti-spacing> </span></span>算法中，将这个长期奖励记为<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值，其中会考虑每个 ”状态<span class=heti-skip><span class=heti-spacing> </span>-<span class=heti-spacing> </span></span>动作“ 的<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值，具体而言，它的计算公式为：</p> <div class=arithmatex>\[ Q(s_{t},a) = R_{t+1} + \gamma \times\max_a Q(a,s_{t+1}) \]</div> <p>也就是对于当前的“状态<span class=heti-skip><span class=heti-spacing> </span>-<span class=heti-spacing> </span></span>动作” <span class=arithmatex>\((s_{t},a)\)</span>，考虑执行动作<span class=heti-skip><span class=heti-spacing> </span><span class=arithmatex>\(a\)</span><span class=heti-spacing> </span></span>后环境奖励<span><span class=heti-spacing> </span><span class=arithmatex>\(R_{t+1}\)</span></span>，以及执行动作<span class=heti-skip><span class=heti-spacing> </span><span class=arithmatex>\(a\)</span><span class=heti-spacing> </span></span>到达<span class=heti-skip><span class=heti-spacing> </span><span class=arithmatex>\(s_{t+1}\)</span><span class=heti-spacing> </span></span>后，执行任意动作能够获得的最大的<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值<span><span class=heti-spacing> </span><span class=arithmatex>\(\max_a Q(a,s_{t+1})\)</span></span>，<span><span class=arithmatex>\(\gamma\)</span><span class=heti-spacing> </span></span>为折扣因子。</p> <p>计算得到新的<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值之后，一般会使用更为保守地更新<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>表的方法，即引入松弛变量<span><span class=heti-spacing> </span><span class=arithmatex>\(alpha\)</span></span> ，按如下的公式进行更新，使得<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>表的迭代变化更为平缓。</p> <div class=arithmatex>\[Q(s_{t},a) = (1-\alpha) \times Q(s_{t},a) + \alpha \times(R_{t+1} + \gamma \times\max_a Q(a,s_{t+1}))\]</div> <h5 id=_13>机器人动作的选择<a class=headerlink href=#_13 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h5> <p>在强化学习中，<strong>探索<span class=heti-skip><span class=heti-spacing> </span>-<span class=heti-spacing> </span></span>利用</strong> 问题是非常重要的问题。 <br> 具体来说，根据上面的定义，会尽可能地让机器人在每次选择最优的决策，来最大化长期奖励。 <br> 但是这样做有如下的弊端： <br> 1. 在初步的学习中，Q 值是不准确的，如果在这个时候都按照 Q 值来选择，那么会造成错误。 2. 学习一段时间后，机器人的路线会相对固定，则机器人无法对环境进行有效的探索。</p> <p>因此需要一种办法，来解决如上的问题，增加机器人的探索。 <br> 通常会使用 <strong>epsilon-greedy</strong> 算法： 1. 在机器人选择动作的时候，以一部分的概率随机选择动作，以一部分的概率按照最优的 Q 值选择动作。 2. 同时，这个选择随机动作的概率应当随着训练的过程逐步减小。</p> <p><img src=http://imgbed.momodel.cn/20200602153554.png width=400> <img src=http://imgbed.momodel.cn/20200601144827.png width=400></p> <h5 id=q-learning><span>Q-Learning<span class=heti-spacing> </span></span>算法的学习过程<a class=headerlink href=#q-learning title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h5> <p><img src=http://imgbed.momodel.cn/20200601170657.png width=900></p> <h5 id=robot><span>Robot<span class=heti-spacing> </span></span>类<a class=headerlink href=#robot title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h5> <p>在本作业中提供了<span class=heti-skip><span class=heti-spacing> </span>QRobot<span class=heti-spacing> </span></span>类，其中实现了<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>表迭代和机器人动作的选择策略，可通过 <code>from QRobot import QRobot</code> 导入使用。</p> <p><strong><span>QRobot<span class=heti-spacing> </span></span>类的核心成员方法</strong></p> <ol> <li>sense_state()：获取当前机器人所处位置</li> </ol> <blockquote> <p>return：机器人所处的位置坐标，如： (0, 0)</p> </blockquote> <ol> <li>current_state_valid_actions()：获取当前机器人可以合法移动的动作</li> </ol> <blockquote> <p>return：由当前合法动作组成的列表，如： ['u','r']</p> </blockquote> <ol> <li>train_update()：以<strong>训练状态</strong>，根据<span class=heti-skip><span class=heti-spacing> </span>QLearning<span class=heti-spacing> </span></span>算法策略执行动作</li> </ol> <blockquote> <p>return：当前选择的动作，以及执行当前动作获得的回报<span class=heti-skip><span class=heti-spacing> </span>,<span class=heti-spacing> </span></span>如： 'u', -1</p> </blockquote> <ol> <li>test_update()：以<strong>测试状态</strong>，根据<span class=heti-skip><span class=heti-spacing> </span>QLearning<span class=heti-spacing> </span></span>算法策略执行动作</li> </ol> <blockquote> <p>return：当前选择的动作，以及执行当前动作获得的回报<span class=heti-skip><span class=heti-spacing> </span>,<span class=heti-spacing> </span></span>如：'u', -1</p> </blockquote> <ol> <li>reset()</li> </ol> <blockquote> <p>return：重置机器人在迷宫中的位置</p> </blockquote> <h4 id=dqn><span>DQN<span class=heti-spacing> </span></span>算法介绍<a class=headerlink href=#dqn title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h4> <p>强化学习是一个反复迭代的过程，每一次迭代要解决两个问题：给定一个策略求值函数，和根据值函数来更新策略。而<span class=heti-skip><span class=heti-spacing> </span>DQN<span class=heti-spacing> </span></span>算法使用神经网络来近似值函数。<span>(<span class=heti-spacing> </span></span><a href=https://files.momodel.cn/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf><span>DQN<span class=heti-spacing> </span></span>论文地址</a><span><span class=heti-spacing> </span>)</span></p> <ul> <li><strong><span>DQN<span class=heti-spacing> </span></span>算法流程</strong></li> </ul> <p><img src=https://imgbed.momodel.cn/20200918101051.png width=60%></p> <ul> <li><strong><span>DQN<span class=heti-spacing> </span></span>算法框架图</strong></li> </ul> <p><img src=https://imgbed.momodel.cn/20200918101137.png width=60%></p> <h5 id=dqn_1>完成<span class=heti-skip><span class=heti-spacing> </span>DQN<span class=heti-spacing> </span></span>算法<a class=headerlink href=#dqn_1 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h5> <p><strong><span>ReplayDataSet<span class=heti-spacing> </span></span>类的核心成员方法</strong></p> <ul> <li><span>add(self, state, action_index, reward, next_state, is_terminal)<span class=heti-spacing> </span></span>添加一条训练数据</li> </ul> <blockquote> <p><span>state:<span class=heti-spacing> </span></span>当前机器人位置</p> <p><span>action_index:<span class=heti-spacing> </span></span>选择执行动作的索引</p> <p>reward： 执行动作获得的回报</p> <p>next_state：执行动作后机器人的位置</p> <p>is_terminal：机器人是否到达了终止节点（到达终点或者撞墙）</p> </blockquote> <ul> <li>random_sample(self, batch_size)：从数据集中随机抽取固定<span class=heti-skip><span class=heti-spacing> </span>batch_size<span class=heti-spacing> </span></span>的数据</li> </ul> <blockquote> <p><span>batch_size:<span class=heti-spacing> </span></span>整数，不允许超过数据集中数据的个数</p> </blockquote> <ul> <li><strong>build_full_view(self, maze)：开启金手指，获取全图视野</strong></li> </ul> <blockquote> <p><span>maze:<span class=heti-spacing> </span></span>以<span class=heti-skip><span class=heti-spacing> </span>Maze<span class=heti-spacing> </span></span>类实例化的对象</p> </blockquote> <h3 id=_14>实现目标<a class=headerlink href=#_14 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <ol> <li><strong>深度优先搜索（DFS）算法</strong>：</li> <li>利用栈结构存储路径节点，从起点开始逐步探索迷宫，记录访问过的位置以避免重复访问。</li> <li> <p>当到达目标点时，利用回溯算法生成完整路径。</p> </li> <li> <p><strong>强化学习（DQN）算法</strong>：</p> </li> <li>初始化<span class=heti-skip><span class=heti-spacing> </span>Q-learning<span class=heti-spacing> </span></span>网络，用于学习状态与动作之间的<span class=heti-skip><span class=heti-spacing> </span>Q<span class=heti-spacing> </span></span>值。</li> <li>通过训练阶段，机器人不断尝试不同路径，并根据奖励函数调整策略。</li> <li> <p>使用贪心策略（epsilon-greedy）平衡探索与利用，最终找到最优路径。</p> </li> <li> <p><strong>奖励函数设计</strong>：</p> </li> <li><code>hit_wall</code><span>:<span class=heti-spacing> </span></span>墙壁碰撞，奖励为正值，惩罚机器人错误动作。</li> <li><code>destination</code><span>:<span class=heti-spacing> </span></span>到达目标点，给予较大的负奖励，鼓励机器人优化路径。</li> <li><code>default</code><span>:<span class=heti-spacing> </span></span>每一步的奖励设为较小的正值，用于保持路径的连续性。</li> </ol> <hr> <h3 id=_15>实验代码<a class=headerlink href=#_15 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <h5 id=1><strong><span>1.<span class=heti-spacing> </span></span>深度优先搜索算法</strong><a class=headerlink href=#1 title="anchor link to this section for reference">¶</a></h5> <p>核心代码实现如下：</p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>my_search</span><span class=p>(</span><span class=n>maze</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""</span>
<span class=sd>    深度优先搜索算法</span>
<span class=sd>    :param maze: 迷宫对象</span>
<span class=sd>    :return :到达目标点的路径 如：["u","u","r",...]</span>
<span class=sd>    """</span>
    <span class=n>path</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>stack</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># 创建⼀个空的栈</span>
    <span class=n>start</span> <span class=o>=</span> <span class=n>maze</span><span class=o>.</span><span class=n>sense_robot</span><span class=p>()</span>
    <span class=n>root</span> <span class=o>=</span> <span class=n>SearchTree</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=n>start</span><span class=p>)</span>
    <span class=n>stack</span> <span class=o>=</span> <span class=p>[</span><span class=n>root</span><span class=p>]</span>  <span class=c1># 根节点压⼊栈中</span>
    <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>maze</span><span class=o>.</span><span class=n>maze_data</span><span class=o>.</span><span class=n>shape</span>
    <span class=n>is_visit_m</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int</span><span class=p>)</span>  <span class=c1># 标记迷宫的各个位置是否被访问过</span>
    
    <span class=k>while</span> <span class=n>stack</span><span class=p>:</span>
        <span class=n>current_node</span> <span class=o>=</span> <span class=n>stack</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>  <span class=c1># 从栈中取出当前节点</span>
        <span class=n>is_visit_m</span><span class=p>[</span><span class=n>current_node</span><span class=o>.</span><span class=n>loc</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>  <span class=c1># 标记当前节点位置已访问</span>
        <span class=c1># 到达⽬标点</span>
        <span class=k>if</span> <span class=n>current_node</span><span class=o>.</span><span class=n>loc</span> <span class=o>==</span> <span class=n>maze</span><span class=o>.</span><span class=n>destination</span><span class=p>:</span>
            <span class=n>path</span> <span class=o>=</span> <span class=n>back_propagation</span><span class=p>(</span><span class=n>current_node</span><span class=p>)</span>
            <span class=k>break</span>
        <span class=c1># 拓展叶节点</span>
        <span class=k>if</span> <span class=n>current_node</span><span class=o>.</span><span class=n>is_leaf</span><span class=p>():</span>
            <span class=n>expand</span><span class=p>(</span><span class=n>maze</span><span class=p>,</span> <span class=n>is_visit_m</span><span class=p>,</span> <span class=n>current_node</span><span class=p>)</span>
        <span class=c1># 将⼦节点⼊栈（逆序）</span>
        <span class=k>for</span> <span class=n>child</span> <span class=ow>in</span> <span class=nb>reversed</span><span class=p>(</span><span class=n>current_node</span><span class=o>.</span><span class=n>children</span><span class=p>):</span>
            <span class=n>stack</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>child</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>path</span>
</code></pre></div> <p>测试代码如下</p> <div class=highlight><pre><span></span><code><span class=n>maze</span> <span class=o>=</span> <span class=n>Maze</span><span class=p>(</span><span class=n>maze_size</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span> <span class=c1># 从文件生成迷宫</span>

<span class=n>path_2</span> <span class=o>=</span> <span class=n>my_search</span><span class=p>(</span><span class=n>maze</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"搜索出的路径："</span><span class=p>,</span> <span class=n>path_2</span><span class=p>)</span>

<span class=k>for</span> <span class=n>action</span> <span class=ow>in</span> <span class=n>path_2</span><span class=p>:</span>
    <span class=n>maze</span><span class=o>.</span><span class=n>move_robot</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>


<span class=k>if</span> <span class=n>maze</span><span class=o>.</span><span class=n>sense_robot</span><span class=p>()</span> <span class=o>==</span> <span class=n>maze</span><span class=o>.</span><span class=n>destination</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>"恭喜你，到达了目标点"</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=n>maze</span><span class=p>)</span>
</code></pre></div> <p>结果如下所示</p> <p><img alt=image-20241118212325438 src=https://zyysite.oss-cn-hangzhou.aliyuncs.com/202411182123542.png></p> <h5 id=2><strong><span>2.<span class=heti-spacing> </span></span>强化学习训练机器人</strong><a class=headerlink href=#2 title="anchor link to this section for reference">¶</a></h5> <p>核心代码实现如下：</p> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>Robot</span><span class=p>(</span><span class=n>TorchRobot</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        训练机器人，直到能够成功走出迷宫</span>
<span class=sd>        """</span>
        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_learn</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=p>))</span>
            <span class=n>success</span> <span class=o>=</span> <span class=kc>False</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>maze_size</span> <span class=o>**</span> <span class=mi>2</span><span class=p>):</span>
                <span class=n>a</span><span class=p>,</span> <span class=n>r</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>test_update</span><span class=p>()</span>
                <span class=k>if</span> <span class=n>r</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>reward</span><span class=p>[</span><span class=s2>"destination"</span><span class=p>]:</span>
                    <span class=k>return</span>

    <span class=k>def</span><span class=w> </span><span class=nf>test_update</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        测试阶段，基于 Q 值选择最佳路径</span>
<span class=sd>        """</span>
        <span class=n>state</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sense_state</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int16</span><span class=p>)</span>
        <span class=n>action</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_choose_best_action</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>
        <span class=n>reward</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>move_robot</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>action</span><span class=p>,</span> <span class=n>reward</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_choose_best_action</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>state</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        选择当前状态下的最优动作</span>
<span class=sd>        """</span>
        <span class=n>state</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>state</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
        <span class=n>q_values</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>eval_model</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>eval_model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>best_action_index</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>q_values</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>valid_action</span><span class=p>[</span><span class=n>best_action_index</span><span class=p>]</span>
</code></pre></div> <h3 id=_16>实验结果<a class=headerlink href=#_16 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h3> <p><img alt=image-20241118213215889 src=https://zyysite.oss-cn-hangzhou.aliyuncs.com/202411182132937.png></p> <ol> <li> <p><strong>深度优先搜索（DFS）结果</strong>：</p> </li> <li> <p>路径规划成功，机器人能够找到从起点到终点的路径。</p> </li> <li>搜索效率较低，路径不一定是最短路径。</li> </ol> <p><img alt=1c2fac08e413ce44bdc181cb6497131 src=https://zyysite.oss-cn-hangzhou.aliyuncs.com/202411182138263.png></p> <ol> <li> <p><strong>强化学习（DQN）结果</strong>：</p> </li> <li> <p>机器人通过训练能够成功找到从起点到终点的最优路径。</p> </li> <li>随着训练的进行，机器人找到的路径逐渐缩短，效率提高。</li> </ol> <p><img alt=image-20241118213802089 src=https://zyysite.oss-cn-hangzhou.aliyuncs.com/202411182138164.png></p> <hr> <h3 id=_17><strong>对比分析</strong><a class=headerlink href=#_17 title="anchor link to this section for reference">¶</a></h3> <table> <thead> <tr> <th>算法</th> <th>优点</th> <th>缺点</th> </tr> </thead> <tbody> <tr> <td>深度优先搜索</td> <td>实现简单，适用于小规模迷宫</td> <td>搜索效率低，路径不一定最优</td> </tr> <tr> <td>强化学习（DQN）</td> <td>能够通过训练找到最优路径，适应复杂动态环境</td> <td>初始训练成本高，对超参数敏感</td> </tr> </tbody> </table> <hr> <h3 id=_18><strong>结论</strong><a class=headerlink href=#_18 title="anchor link to this section for reference">¶</a></h3> <ol> <li>深度优先搜索适用于小规模迷宫环境，算法实现简单，但对复杂迷宫不够高效。</li> <li>深度强化学习（DQN）算法能够通过训练找到最优路径，且适用于复杂迷宫环境，但需要较多训练时间。</li> <li>实验验证了强化学习在路径规划领域的潜力，同时也展示了传统算法在特定场景中的优势。</li> </ol> <hr> <h3 id=_19><strong>改进方向</strong><a class=headerlink href=#_19 title="anchor link to this section for reference">¶</a></h3> <ol> <li>优化强化学习的超参数，如学习率、奖励函数权重。</li> <li>将深度优先搜索与强化学习结合，利用传统算法指导初始训练。</li> <li>扩展迷宫环境的复杂性，测试算法在动态迷宫中的性能。</li> </ol> <h2 id=_20>附录<a class=headerlink href=#_20 title="anchor link to this section for reference"><span><span class=heti-spacing> </span>¶</span></a></h2> <h3 id=mainpy>Main.py<a class=headerlink href=#mainpy title="anchor link to this section for reference">¶</a></h3> <div class=highlight><pre><span></span><code><span class=c1># 导入相关包</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>
<span class=kn>import</span><span class=w> </span><span class=nn>random</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>Maze</span><span class=w> </span><span class=kn>import</span> <span class=n>Maze</span>
<span class=kn>from</span><span class=w> </span><span class=nn>Runner</span><span class=w> </span><span class=kn>import</span> <span class=n>Runner</span>
<span class=kn>from</span><span class=w> </span><span class=nn>QRobot</span><span class=w> </span><span class=kn>import</span> <span class=n>QRobot</span>
<span class=kn>from</span><span class=w> </span><span class=nn>ReplayDataSet</span><span class=w> </span><span class=kn>import</span> <span class=n>ReplayDataSet</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch_py.MinDQNRobot</span><span class=w> </span><span class=kn>import</span> <span class=n>MinDQNRobot</span> <span class=k>as</span> <span class=n>TorchRobot</span> <span class=c1># PyTorch版本</span>
<span class=kn>from</span><span class=w> </span><span class=nn>keras_py.MinDQNRobot</span><span class=w> </span><span class=kn>import</span> <span class=n>MinDQNRobot</span> <span class=k>as</span> <span class=n>KerasRobot</span> <span class=c1># Keras版本</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>


<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># 机器人移动方向</span>
<span class=n>move_map</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>'u'</span><span class=p>:</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=c1># up</span>
    <span class=s1>'r'</span><span class=p>:</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=c1># right</span>
    <span class=s1>'d'</span><span class=p>:</span> <span class=p>(</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=c1># down</span>
    <span class=s1>'l'</span><span class=p>:</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=c1># left</span>
<span class=p>}</span>


<span class=c1># 迷宫路径搜索树</span>
<span class=k>class</span><span class=w> </span><span class=nc>SearchTree</span><span class=p>(</span><span class=nb>object</span><span class=p>):</span>


    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=p>(),</span> <span class=n>action</span><span class=o>=</span><span class=s1>''</span><span class=p>,</span> <span class=n>parent</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        初始化搜索树节点对象</span>
<span class=sd>        :param loc: 新节点的机器人所处位置</span>
<span class=sd>        :param action: 新节点的对应的移动方向</span>
<span class=sd>        :param parent: 新节点的父辈节点</span>
<span class=sd>        """</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>loc</span> <span class=o>=</span> <span class=n>loc</span>  <span class=c1># 当前节点位置</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>to_this_action</span> <span class=o>=</span> <span class=n>action</span>  <span class=c1># 到达当前节点的动作</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>parent</span> <span class=o>=</span> <span class=n>parent</span>  <span class=c1># 当前节点的父节点</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>children</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># 当前节点的子节点</span>

    <span class=k>def</span><span class=w> </span><span class=nf>add_child</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>child</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        添加子节点</span>
<span class=sd>        :param child:待添加的子节点</span>
<span class=sd>        """</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>children</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>child</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>is_leaf</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        判断当前节点是否是叶子节点</span>
<span class=sd>        """</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>children</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span>


<span class=k>def</span><span class=w> </span><span class=nf>expand</span><span class=p>(</span><span class=n>maze</span><span class=p>,</span> <span class=n>is_visit_m</span><span class=p>,</span> <span class=n>node</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""</span>
<span class=sd>    拓展叶子节点，即为当前的叶子节点添加执行合法动作后到达的子节点</span>
<span class=sd>    :param maze: 迷宫对象</span>
<span class=sd>    :param is_visit_m: 记录迷宫每个位置是否访问的矩阵</span>
<span class=sd>    :param node: 待拓展的叶子节点</span>
<span class=sd>    """</span>
    <span class=n>can_move</span> <span class=o>=</span> <span class=n>maze</span><span class=o>.</span><span class=n>can_move_actions</span><span class=p>(</span><span class=n>node</span><span class=o>.</span><span class=n>loc</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=n>can_move</span><span class=p>:</span>
        <span class=n>new_loc</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>node</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>move_map</span><span class=p>[</span><span class=n>a</span><span class=p>][</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>is_visit_m</span><span class=p>[</span><span class=n>new_loc</span><span class=p>]:</span>
            <span class=n>child</span> <span class=o>=</span> <span class=n>SearchTree</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=n>new_loc</span><span class=p>,</span> <span class=n>action</span><span class=o>=</span><span class=n>a</span><span class=p>,</span> <span class=n>parent</span><span class=o>=</span><span class=n>node</span><span class=p>)</span>
            <span class=n>node</span><span class=o>.</span><span class=n>add_child</span><span class=p>(</span><span class=n>child</span><span class=p>)</span>


<span class=k>def</span><span class=w> </span><span class=nf>back_propagation</span><span class=p>(</span><span class=n>node</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""</span>
<span class=sd>    回溯并记录节点路径</span>
<span class=sd>    :param node: 待回溯节点</span>
<span class=sd>    :return: 回溯路径</span>
<span class=sd>    """</span>
    <span class=n>path</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>while</span> <span class=n>node</span><span class=o>.</span><span class=n>parent</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>path</span><span class=o>.</span><span class=n>insert</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>node</span><span class=o>.</span><span class=n>to_this_action</span><span class=p>)</span>
        <span class=n>node</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>parent</span>
    <span class=k>return</span> <span class=n>path</span>


<span class=k>def</span><span class=w> </span><span class=nf>my_search</span><span class=p>(</span><span class=n>maze</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""</span>
<span class=sd>    深度优先搜索算法</span>
<span class=sd>    :param maze: 迷宫对象</span>
<span class=sd>    :return :到达目标点的路径 如：["u","u","r",...]</span>
<span class=sd>    """</span>

    <span class=n>path</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=c1># -----------------请实现你的算法代码--------------------------------------</span>
    <span class=n>stack</span> <span class=o>=</span> <span class=p>[]</span> <span class=c1># 创建⼀个空的栈</span>
    <span class=n>start</span> <span class=o>=</span> <span class=n>maze</span><span class=o>.</span><span class=n>sense_robot</span><span class=p>()</span>
    <span class=n>root</span> <span class=o>=</span> <span class=n>SearchTree</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=n>start</span><span class=p>)</span>
    <span class=n>stack</span> <span class=o>=</span> <span class=p>[</span><span class=n>root</span><span class=p>]</span> <span class=c1># 根节点压⼊栈中</span>
    <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>maze</span><span class=o>.</span><span class=n>maze_data</span><span class=o>.</span><span class=n>shape</span>
    <span class=n>is_visit_m</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int</span><span class=p>)</span> <span class=c1># 标记迷宫的各个位置是否被访问过</span>
    
    <span class=k>while</span> <span class=n>stack</span><span class=p>:</span>
        <span class=n>current_node</span> <span class=o>=</span> <span class=n>stack</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span> <span class=c1>#从栈中取出当前节点</span>
        <span class=n>is_visit_m</span><span class=p>[</span><span class=n>current_node</span><span class=o>.</span><span class=n>loc</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span> <span class=c1># 标记当前节点位置已访问</span>
        <span class=c1># 到达⽬标点</span>
        <span class=k>if</span> <span class=n>current_node</span><span class=o>.</span><span class=n>loc</span> <span class=o>==</span> <span class=n>maze</span><span class=o>.</span><span class=n>destination</span><span class=p>:</span>
            <span class=n>path</span> <span class=o>=</span> <span class=n>back_propagation</span><span class=p>(</span><span class=n>current_node</span><span class=p>)</span>
            <span class=k>break</span>
        <span class=c1># 拓展叶节点</span>
        <span class=k>if</span> <span class=n>current_node</span><span class=o>.</span><span class=n>is_leaf</span><span class=p>():</span>
            <span class=n>expand</span><span class=p>(</span><span class=n>maze</span><span class=p>,</span> <span class=n>is_visit_m</span><span class=p>,</span> <span class=n>current_node</span><span class=p>)</span>
        <span class=c1># 将⼦节点⼊栈（逆序）</span>
        <span class=k>for</span> <span class=n>child</span> <span class=ow>in</span> <span class=nb>reversed</span><span class=p>(</span><span class=n>current_node</span><span class=o>.</span><span class=n>children</span><span class=p>):</span>
            <span class=n>stack</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>child</span><span class=p>)</span>
    <span class=c1># -----------------------------------------------------------------------</span>
    <span class=k>return</span> <span class=n>path</span>


<span class=kn>import</span><span class=w> </span><span class=nn>os</span>
<span class=kn>import</span><span class=w> </span><span class=nn>random</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>from</span><span class=w> </span><span class=nn>QRobot</span><span class=w> </span><span class=kn>import</span> <span class=n>QRobot</span>
<span class=kn>from</span><span class=w> </span><span class=nn>ReplayDataSet</span><span class=w> </span><span class=kn>import</span> <span class=n>ReplayDataSet</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch_py.MinDQNRobot</span><span class=w> </span><span class=kn>import</span> <span class=n>MinDQNRobot</span> <span class=k>as</span> <span class=n>TorchRobot</span> <span class=c1># PyTorch版本</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>class</span><span class=w> </span><span class=nc>Robot</span><span class=p>(</span><span class=n>TorchRobot</span><span class=p>):</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>maze</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        初始化 Robot 类</span>
<span class=sd>        :param maze:迷宫对象</span>
<span class=sd>        """</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>Robot</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>maze</span><span class=p>)</span>
        <span class=n>maze</span><span class=o>.</span><span class=n>set_reward</span><span class=p>(</span><span class=n>reward</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>"hit_wall"</span><span class=p>:</span> <span class=mf>10.</span><span class=p>,</span>
            <span class=s2>"destination"</span><span class=p>:</span> <span class=o>-</span><span class=n>maze</span><span class=o>.</span><span class=n>maze_size</span> <span class=o>**</span> <span class=mi>2</span> <span class=o>*</span><span class=mi>10</span><span class=p>,</span>
            <span class=s2>"default"</span><span class=p>:</span> <span class=mf>1.</span><span class=p>,</span>
        <span class=p>})</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>maze</span> <span class=o>=</span> <span class=n>maze</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>epsilon</span> <span class=o>=</span> <span class=mi>0</span>
<span class=w>        </span><span class=sd>"""开启金手指，获取全图视野"""</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=o>.</span><span class=n>build_full_view</span><span class=p>(</span><span class=n>maze</span><span class=o>=</span><span class=n>maze</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
        

    <span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>      
        <span class=c1># 训练，直到能走出这个迷宫</span>
        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_learn</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=p>)</span> <span class=p>)</span>
            <span class=n>success</span> <span class=o>=</span> <span class=kc>False</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>maze_size</span> <span class=o>**</span> <span class=mi>2</span> <span class=p>):</span>
                <span class=n>a</span><span class=p>,</span> <span class=n>r</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>test_update</span><span class=p>()</span>
                <span class=k>if</span> <span class=n>r</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>reward</span><span class=p>[</span><span class=s2>"destination"</span><span class=p>]:</span>
                    <span class=k>return</span> 

    <span class=k>def</span><span class=w> </span><span class=nf>train_update</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>state</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sense_state</span><span class=p>()</span>
        <span class=n>action</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_choose_action</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>
        <span class=n>reward</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>move_robot</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
        
        <span class=k>return</span> <span class=n>action</span><span class=p>,</span> <span class=n>reward</span>
    
    
    <span class=k>def</span><span class=w> </span><span class=nf>test_update</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=c1># 获取当前状态</span>
        <span class=n>state</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sense_state</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int16</span><span class=p>)</span>
        <span class=c1># 根据Q表选择最佳动作</span>
        <span class=n>action</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_choose_best_action</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>
        <span class=c1># 执行动作并获得奖励</span>
        <span class=n>reward</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maze</span><span class=o>.</span><span class=n>move_robot</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
        <span class=c1># 返回动作和奖励</span>
        <span class=k>return</span> <span class=n>action</span><span class=p>,</span> <span class=n>reward</span>
    
    <span class=k>def</span><span class=w> </span><span class=nf>_choose_best_action</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>state</span><span class=p>):</span>
        <span class=n>state</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>state</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
        <span class=n>q_values</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>eval_model</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>  <span class=c1># 假设这个方法返回给定状态下所有动作的Q值</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>eval_model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>best_action_index</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>q_values</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>valid_action</span><span class=p>[</span><span class=n>best_action_index</span><span class=p>]</span>  <span class=c1># 假设valid_actions是所有可能动作的列表</span>
</code></pre></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最后更新> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime">2024年12月26日 00:51:51</span> </span> <span class=md-source-file__fact> <span class=md-icon title=创建日期> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime">2024年12月26日 00:51:51</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright <span style=font-family:Arial;>©</span> 2023-2024 <a href=https://github.com/awslasasd target=_blank>awslasasd</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ rel=noopener target=_blank> Material for MkDocs </a> </div> <div class=md-social> <a class=md-social__link href=https://github.com/awslasasd rel=noopener target=_blank title="awslasasd's Profile"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.path", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.instant", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.code.annotate", "content.code.copy", "content.tabs.link", "announce.dismiss"], "search": "../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../../../assets/javascripts/bundle.fe8b6f2b.min.js></script> <script src=../../../../style/js/toc.js></script> <script src=../../../../style/js/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>