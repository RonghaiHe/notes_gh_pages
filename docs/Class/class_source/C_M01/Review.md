# 复习

## 重要概念

- 人工智能概念的一般描述：“人工智能”一词目前是指用计算机模拟或实现的智能， 研究如何在机器上实现人类智能。即用机器来模仿人的智能。因此人工智能又称机器智能。
- 智能包含的能力：感知能力、记忆和思维能力、学习和自适应能力、行为能力
- 人工智能的定义：人工智能是研究人类智能活动的规律，构造具有一定智能的人工系统，研究如何让计算机去完成以往需要人的智力才能胜任的工作，也就是研究如何应用计算机的软硬件来模拟人类某些智能行为的基本理论、方法和技术。
- 人工智能定义总结为4类：像人一样思考、像人一样行动、合理的思考、合理的行动
- 图灵测试：判断机器是否能够展现出与人类不可区分的智能行为，被认为具有人类智能
- 现代控制论和AI的共同点：设计出能随时最大化目标函数的系统
- 人工智能技术发展三个阶段：人工智能起步期、专家系统推广、深度学习
- 人工智能三次低谷：英国发表James Lighthill 报告、日本智能（第五代）计算机研制失败、知识词典日趋势微、网络百科兴起
- 人工智能两大研究内容：智能机器、智能系统
- 三大学派：符号学派、连接学派、行为学派
- 人工智能的三个阶段：能存会算的计算智能、能听会说、能看会认的感知智能、能理解会思考的认知智能
- 应用：专家系统、机器人、模式识别、计算机视觉、人工神经网络、自然语言理解、自动程序设计、博弈、自主规划和调度、自主控制、后勤规划



- 智能体（agent）：指能够感知和动作的实体，一个智能体就是从**感知序列到动作**的一个函数： $f:P^* -> A$
- 理性Agent：对于每一个可能的感知序列，根据已知的感知序列和内建的先验知识，理性Agent选择能使性能指标的期望值最大化的动作。
- PEAC：Performance性能、Enviroment  环境、Actuators  执行器、Sensors    传感器
- 智能体(结构）类型：简单反射型、基于模型的简单反射型、基于目标型、基于效用型
- 智能体特性：自主性、反应性、适应性、社会性
- 性能度量评价智能体在环境中的行为表现。理性智能体的行动使其性能度量期望值最大化
- 任务环境包括性能度量、外部环境、执行器和传感器。设计智能体的第一步总是把任务空间定义得尽可能完全。
- 所有智能体都可以通过学习来改进其性能
- 智能体程序是智能体函数的实现



- 问题求解智能体设计的基本步骤：目标形式化、问题形式化、搜索、执行
- 良定义的问题：初始状态，可能行动，转移模型，目标测试函数，路径耗散（代价、成本）函数
- 搜索三要素：状态空间、后继函数、初始状态和目标测试
- DFS：不完备、非最优
- BFS：完备、最优（如果每步的耗散为1，或路径耗散是节点深度的非递减函数）
- 迭代加深：完备、最优（如果步增成本=1）



- 评价函数：f(n) 、 路径消耗函数g(n)、最小路径耗散估计h(n)
- 贪婪算法：非完备、非最优；如果没有重复状态检测，会陷入循环
- A *算法：完备、最优
- 递归最佳优先搜索(RBFS)和简化存储限制A * (SMA * )是鲁棒、最优的搜索算法，只使用有限的内存。在时间足够的条件下，能求解A*算法难以求解的问题。



- 竞争环境中多个agent之间的目标是有冲突的，称为对抗搜索问题，也称为博弈
- MinMax：完备（树是有限的）最优（对手总是最优时）



- 一个智能程序高水平的运行需要有关的事实知识、规则知识、控制知识和元知识。
- 知识特性：相对正确性、不正确性、可表示性
- 知识分类：范围、作用、确定、表现、抽象
- 语言：由语音、词汇和语法构成一定的系统。分为自然语言、形式语言
- 命题（proposition）：是具有真假意义的语句。
- 论域/个体/个体间关系/作用于个体函数 这4个成分构成了一阶逻辑的结构
- 在一阶逻辑中，被研究对象构成的非空集称为论域；论域中的每个元素称为个体（对象）
- 一阶逻辑研究个体的性质、个体之间的关系及作用于个体的函数
- 能够独立存在的事物，称之为客体，也称之为个体。
- 一阶形式语言中用于指称论域中个体的性质或者个体之间关系的形式符号（大写字母表示）
- 为了表达个体之间的对应关系，引入数学中函数概念和记法。（用小写字母）

- 谓词和函数的区别：谓词代表**语句**，结果是关系（具有真假值）；函数代表关系运算，**结果是一个新个体**
- 在命题中表示对客体数量化的词，称之为 量词。 
- 区别：自由变量可代入常量，约束变量不行，因为a P(a)无意义 ；约束变量可改名，自由变量不行
- 谓词公式的永真性、可满足性、不可满足性



- 分类问题与回归问题均属于有监督学习
- 无监督学习主要用于聚类、降维、异常检测、关联规则挖掘
- 激活函数的作用：为网络引入非线性
- 阶跃函数缺点：具有不连续、不光滑等性质
- 训练一个神经网络需要：构建数据集、构建网络模型、设定损失函数、选取迭代更新参数的优化器
- 训练一个神经网络的基本步骤：神经网络初始化、正向传播、计算总损失、反向传播、对每个参数进行迭代更新
- 构建数据集：训练集、测试集、验证集
- 分类任务损失函数：二分类：Binary Cross Entropy；多分类：Categorical Cross Entropy；（还有Balanced Cross Entropy、Focal Loss等等，可以解决不同类别样本数量不均衡的问题）
- 回归任务损失函数：平均绝对误差 MAE / L1 Loss ；均方误差 MSE / L2 Loss；Smooth L1 Loss
- 优化器包括：SGD、Momentum、NAG、Adagrad、RMSprop、Adadelta、Adam 等
- 反向传播的关键：链式法则
- 梯度消失与梯度爆炸出现的原因基本一致，一般可能是网络层数过深、激活函数、损失函数设置与参数初始化问题，求梯度过程某个值过大过小或链式法则层数过多导致累积效果过大
- 学习率是优化算法中可设定的超参数，该参数可确定确定每次迭代中的步长，使损失函数收敛到最小值，学习率的设定很有讲究，若设置**太大则容易引起振荡，若设置太小则会导致收敛速度过慢**
- 批量梯度下降、随机梯度下降与mini-batch梯度下降



## 23-24自动化回忆卷

### 选择（单多选混杂）

1.哪个不属于人工智能的运用 

> 属于的有：专家系统、机器人、模式识别、计算机视觉、人工神经网络、博弈

2.下列哪个算法是按照某种规则遍历搜索空间的算法 

a. dfs b. bfs c. a* d.优先级搜索 

> A、B

3.机器学习是 

a.人工智能的一种分支 b.数据分析的一种技术 

> A、B

4.下面哪种算法不是盲目搜索 

> 启发式搜索都不是

5.欠拟合定义 

> 训练集表现差，在测试集表现同样会很差

6.下面哪些是常用的算法评价指标 

a. 准确率召回率 b. MSE c. MAE d.AUC-ROC曲线

> A、B、C、D

7.下面哪些指标可以评价回归 

a. MAE b. MSE c. binary cross-entropy d. L1-smooth 

> A、B、D

8.贝叶斯计算 

9.下面哪种算法属于强化学习 

> 基于值的算法：Q-learning DQN SARSA<br>基于策略的算法：PPO

10.人类智能的定义 

> 指人在认识客观世界的过程中，由思维过程和脑力活动所表现出来的综合能力

11.如果假设空间很大，应该用哪种方法搜索 

> A *

12.人脸检测的方法顺序 有特征点匹配什么的 

13.存在最优解，哪个算法能找到 

a.BFS b.启发式 c. DFS d.有限深度 

> A 、D

14.下面哪个子集不可满足       

a.{....，非p，p}       b.{p并q，非p并q，p并非q，非p并非q} 

> A、B

15.概念学习定义

> 属于模型驱动学习中的一种，从给定的某一类别的若干正例和反例中获得该类别的一般定义

16.通过图灵测试，则可以认为

> 从表现上来说，能够实现与人相似的智能



### 填空

 f(n)=g(n)+h(n)中g(n)和h(n)的含义，g(n)是**从起始点到当前点n的实际耗散，叫实际代价函数**，h(n)是**从当前点n到目标点的最小路径耗散估计。叫估计代价函数**

人工智能的三个学派分别是**符号学派、连接学派、行为学派**

人工智能的短期目标和长期目标分别是：**制造智能机器和实现机器智能**

BFS存储待搜索节点的数据结构**队列**，DFS存储已搜索节点的数据结构**栈**

根据Agent是否理解其所处的环境，将强化学习分为**无模型的强化学习**和**基于模型的强化学习**

Find-S用**特殊到一般（more_general_than）**的方法，在**偏序**结构上实现，每一步得到的假设都是在那一点上与训练样例一致的**最特殊**的假设



### 简答



 **1.根据极大极小算法，简述alpha-beta剪枝的原理然后完成剪枝**

极大极小算法的基本思想是：极大玩家希望最大化自己的得分，而极小玩家则希望最小化极大玩家的得分。算法通过递归地评估所有可能的走法来实现这一点。Alpha-Beta剪枝是一种优化极大极小算法的方法，用于减少搜索树中需要评估的节点数量。其核心思想是通过在搜索过程中记录已经得到的最优解，来避免对某些分支的进一步搜索。

```text
        MAX
       /   \
      MIN   MIN
     / \   / \
    3   5 2   9
```

- 初始时，alpha = -∞，beta = +∞。

- MAX节点开始搜索：

  \quad \quad 访问第一个MIN节点，得到3，更新alpha = max(-∞, 3) = 3。<br>
  \quad \quad  访问第二个MIN节点，得到2，因为2 < alpha，剪枝，不再继续搜索该分支。

- MAX节点返回3作为最优解。

通过Alpha-Beta剪枝，可以有效地减少搜索树的大小，提高算法的效率。



**2.已知“凡是干净的东西就有人喜欢”“没人喜欢苍蝇” （1）定义谓词 （2）写出逻辑表达式 （3）转换为标准子句 （4）利用归结原理证明“苍蝇不干净”**



（1）干净的C(x), x喜欢y->Like(x,y) 人P(x) 苍蝇F(x)

（2）

$$
\begin{aligned}
\forall x \ (C(x) \to \exist y\ P(y)\land Like(y,x)) \\
\forall x\forall y \ (F(x)\land P(y) \to  \lnot Like(y,x)) \\
结论：\forall x(F(x)\to \lnot C(x))
\end{aligned}
$$

（3）

求题设与结论否定的子句集：

$$
\begin{aligned}
转化过程： \\
\lnot C(x) \lor (P(f(x)) \land Like(f(x),x)) \\
(\lnot C(x) \lor P(f(x))) \land (\lnot C(x)\lor Like(f(x),x)) \\
 \\
\lnot(F(x)\land P(y))\lor \lnot Like(y,x) \\
\lnot F(x)\lor \lnot P(y)\lor \lnot Like(y,x) \\
 \\
\lnot F(x) \lor \lnot C(x) \\
\\
结论的取否定 \\
R1： \lnot C(x) \lor P(f(x)) \\
R2： \lnot C(x)\lor Like(f(x),x) \\
R3： \lnot F(x)\lor \lnot P(y)\lor \lnot Like(y,x) \\
R4： F(x) \\
R5： C(x) \\
\end{aligned}
$$

（4）

$$
\begin{aligned}
\\根据归结原理： \\
R6： \ P(f(x))   \\
R7： \ Like(f(x),x) \\
R8： \lnot P(y)\lor \lnot Like(y,x) \\
R9： \lnot Like(f(x),x) \\
R10： NIL
\end{aligned}
$$

所以苍蝇是不干净的



**3.过控流程中有数据收集与分析、系统建模、控制系统设计、离线验证与测试、实地部署。请你设计流程，用至少三种本门课学习的方法解决可能遇到的问题，并说明可行性**

系统建模：采用强化学习方法，如Q-learning或策略梯度算法，来学习系统的动态行为。强化学习通过与环境的交互来学习最优策略，能够适应环境的变化。

控制系统设计：使用优化算法，如遗传算法，同时考虑多个性能指标，如稳定性、响应速度、能耗等，来优化控制策略。能够在多目标优化问题中找到平衡各目标的最优解。

数据收集与分析：在数据收集过程中，可能会遇到数据缺失、不确定性较高的问题，利用贝叶斯估计通过先验知识和观察数据来更新对参数的估计，从而在数据不完整的情况下也能获得较为可靠的分析结果



**4.描述决策树的原理和优缺点**

决策树是一种基于树结构的分类和回归模型。其核心原理是通过递归地选择最优特征对数据集进行分割，构建出一棵树形结构，每个节点代表一个特征判断，每个分支代表一个判断结果，每个叶子节点代表一个预测结果。在特征选择上，常用信息增益、增益率或基尼不纯度等指标来衡量特征的有效性。

决策树的优点包括模型直观易理解、可处理数值型和分类型数据、无需对数据进行归一化处理等；

缺点则包括容易过拟合、对数据中的噪声比较敏感、在某些情况下分类边界不够平滑等。

为了解决过拟合问题，通常需要对决策树进行剪枝处理。



**5.描述朴素贝叶斯分类器的原理和应用场景**

朴素贝叶斯分类器是一种基于贝叶斯定理的简单概率分类器，其核心假设是特征之间相互独立。具体来说，它通过计算给定特征条件下各个类别的后验概率，选择概率最大的类别作为预测结果。

应用场景：

1. **文本分类**：广泛应用于垃圾邮件过滤、新闻文章分类等任务。由于文本数据中词汇之间的独立性假设在一定程度上成立，朴素贝叶斯能够有效地处理大规模文本数据。
2. **情感分析**：用于分析文本中的情感倾向，如评论、社交媒体帖子等，判断其是正面、负面还是中性情感。
3. **推荐系统**：在某些推荐场景中，朴素贝叶斯可以用于预测用户对商品或内容的兴趣偏好，从而提供个性化的推荐。



**6.描述梯度消失的概念和影响，谈谈自己的理解**

梯度消失是指在深度神经网络训练过程中，随着网络层数的增加，某些层的梯度变得非常小，导致在反向传播时无法有效更新这些层的权重。这种情况通常发生在使用Sigmoid或Tanh等激活函数的深层网络中，因为这些函数的导数在输入值较大或较小时接近于零，使得梯度在多层传播过程中逐渐减小，甚至趋近于零.

1. **训练困难**：梯度消失使得网络中较深层的权重更新非常缓慢，导致训练过程缓慢甚至停滞不前，难以收敛到一个有效的解.
2. **性能受限**：由于深层网络无法得到有效训练，模型无法充分利用深层结构的优势来捕捉复杂的数据特征和模式，从而限制了模型的性能和泛化能力.
3. **网络深度受限**：梯度消失问题限制了网络的深度，使得在实际应用中难以构建非常深的网络结构，而深度是提升模型复杂性和表达能力的重要因素.



**7.介绍Q-Learning并说明在强化学习中的作用**

Q-Learning是一种无模型的强化学习算法，用于学习在给定状态下选择动作以最大化长期累积奖励的最优策略。它通过构建一个Q表来记录每个状态-动作对的预期回报，并通过与环境的交互来更新Q表。具体过程包括：初始化Q表，选择动作（通过ε-greedy策略平衡探索与利用），执行动作并观察奖励和新状态，然后根据贝尔曼方程更新Q值。Q-Learning的优势在于无需环境模型，只需通过交互学习策略，使其在不确定的环境中有效工作。此外，其结构简单，易于实现，适合离散状态和动作空间的问题。Q-Learning在强化学习中提供了一种基础而强大的方法，广泛应用于游戏AI、机器人控制、推荐系统等领域，帮助智能体在复杂环境中做出最优决策，提升其性能和适应能力.



## 22-23自动化回忆卷

### 选择

**1.人工智能定义**

人工智能是研究人类智能活动的规律，构造具有一定智能的人工系统，研究如何让计算机去完成以往需要人的智力才能胜任的工作，也就是研究如何应用计算机的软硬件来模拟人类某些智能行为的基本理论、方法和技术。



**2.k折交叉验证,正确的是**

A. k 越大 , 不一定越好 , 选择大的 k 会加大评估时间

B. 选择更大的k, 就会有更小的bias (因为训练集更加接近总数据集)

C. 在选择k时, 要最小化数据集之间的方差

D. 以上所有

> 答案：D。这些都是关于k折交叉验证的正确描述。<br>
> k越大，就要训练k个模型，计算量越大，所以时间更多；k越大，每次选取的训练集越接近总数据集，所以bias越小；



**3.Naive Bayes** **是一种特殊的** **Bayes** **分类器，特征变量是** **X****，类别标签是** **C****，它的一个假定是（）

A. 各类别的先验概率 P(C) 是相等的

B. 以0为均值，sqr(2)/2为标准差的正态分布

C. 特征变量X的各个维度是类别条件独立随机变量

D. P(X|C)是高斯分布

>  答案：C。朴素贝叶斯的核心假设是特征条件独立性即iid假设



**4.假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是（）**

​    A. 这个被重复的特征在模型中的决定作用会被加强 

​    B. 模型效果相比无重复特征的情况下精确度会降低 

​    C. 如果所有特征都被重复一遍，得到的模型预测结果相对于不重复的情况下的模型预测结果一样

​    D. 当两列特征高度相关时，无法用两列特征相同时所得到的结论来分析问题 

​    E. NB可以用来做最小二乘回归 

​    F. 以上说法都不正确

> 答案：BD [假定某同学使用Naive Bayesian（NB）分类模型时\_\_牛客网](https://www.nowcoder.com/questionTerminal/f25c433b9b0d42659d2cf3b39a8367ae)<br>
> A. 看D就知道，如果两个维度比较相似，那么这两个维度可能高度相关，那么就需要转到D。<br>
> B. 当维度重复时，习得的联合概率分布有误，所以精确度会降低。<br>
> C. 多出一个维度的特征，其训练出的模型就会有所不同。这与把两个维度的值重复的情况是不同的。<br>
> D.两列特征高度相关时（也就是有可能是因为重复了），那就无法用这种疑似重复的特征来分析问题了。<br>
> E.最小二乘回归是用在判别式的机器学习方法中，比如SVM,logtic等。它是寻找几何误差最小的预测模型。而贝叶斯是生成式模型。<br>



**5.下列属于无监督学习的是（）**

A. k-means

B. SVM

C. 最大熵

D. CRF (条件随机场,一种判别式概率无向图模型,常用于序列标注任务)

> 答案：A。k-means是一种典型的无监督聚类算法。



**6.在多层感知器中，激活函数的作用是**

A. 引入非线性 B. 确定神经元的输出 C. 计算损失函数 D. 控制神经元的输入

> 答案：A。



**7.深度优先算法的实现**

用栈实现。



**8.训练决策树模型，属性节点的分裂，具有最大信息增益的图是哪一个（）**

![](https://zyysite.oss-cn-hangzhou.aliyuncs.com/202501082015366.png)

A. Outlook

B. Humidity

C. Windy

D. Temperature

> 答案：A。根据图中信息增益的计算，Outlook具有最大的信息增益



**9.命题逻辑**

不知道想干嘛



**10.二分类，多分类，回归，聚类的区别**



**11.什么时候梯度下降会卡住**

A. ![](https://zyysite.oss-cn-hangzhou.aliyuncs.com/202501082013908.png)

​    B. ![](https://zyysite.oss-cn-hangzhou.aliyuncs.com/202501082013899.png)

​    C. ![](https://zyysite.oss-cn-hangzhou.aliyuncs.com/202501082013902.png)

​    D. 以上都不正确



> 答案：B。在局部最小值点处，梯度为0，一阶梯度下降可能会停止。



**12.如果问题存在最优解，则下面几种搜索算法中，（ ）可以认为是“智能程度相对比较高”的算法。**

 A. 深度优先搜索 B. 宽度优先搜索 C. 有界深度优先搜索 D.启发式搜索 

> 答案D



**13.非(P 且 Q)=(非 P)或(非 Q)**

> 摩根定律



**14.人类智能具有的4项特性为**

> 自主性、反应性、适应性、社会性



**15.下列不属于知识的特征的有（）**

> 相对正确性、不确定性、可表示性



**16.下列说法错误的有**

 A 宽度优先搜索可以看作一致代价搜索的特殊情况 B 一致代价搜索可看作A*搜索的特殊情况 C 贪婪最佳优先搜索是完备的 D 爬山法可以到达起点附近的最佳点

> C



**17.强化学习算法可以分为有模型学习（model-based）算法和免模型（model-free）学习算法，以下属于有模型学习算法的是**

A. Policy Gradient

B. Deep Deterministic Policy Gradient (DDPG)

C. Deep Q Network (DQN)

D. AlphaZero

> 答案：D



### 填空

**1.智能的四种能力**

感知能力、学习和自适应能力、记忆和思维能力、行为能力

**2.人工智能的短期和终极目标**

短期：制造智能机器，实现机器智能

**3.P为原子谓词公式，则P和~P为_**__

互补关系

**4.**Find-S用**特殊到一般（more_general_than）**的方法，在**偏序**结构上实现，每一步得到的假设都是在那一点上与训练样例一致的**最特殊**的假设

**5.若P,R为F，Q为T，则（P or R）-> Q为___** 

T

**6.Teacher(father(Zhan))的个体是**

Zhan、father(Zhan)



**7.谓词和函数的区别**

谓词代表语句，结果是关系（具有真假值）；函数代表关系运算，结果是一个新个体



### 简答

**1.博弈树倒推值和αβ剪枝条原理，以及该剪去哪些枝条。**



**2.A*搜索里的g(n)和h(n)表示什么**

 f(n)=g(n)+h(n)中g(n)和h(n)的含义，g(n)是从起始点到当前点n的实际耗散，叫实际代价函数，h(n)是从当前点n到目标点的最小路径耗散估计。叫估计代价函数



**3.赵钱孙李四个人有人作案。A说赵和钱必有一个偷东西，B说钱和孙必有一个偷了，C说孙和李必有一个偷了，D说赵和孙必有一个没偷，E说钱和李必有一个没偷。要用归结的方式证明是谁偷了东西**

$$
\begin{aligned}
P(zhao)\lor P(qian)\\
P(qian)\lor P(sun)\\
P(sun)\lor P(li)\\
\neg P(zhao)\lor \neg P(sun)\\
\neg P(qian)\lor \neg P(li)
\end{aligned}
$$

猜测是钱和孙偷的，故将结论取反

$$
\neg P(qian) \\
\neg P(sun)
$$

（8） P(qian) ∨ ﹁P(sun)         (1)与(4)归结

（9） P(zhao) ∨ ﹁P(li)         (1)与(5)归结

（10） P(qian) ∨ ﹁P(zhao)        (2)与(4)归结

（11） P(sun) ∨﹁P(li)          (2)与(5)归结

（12） ﹁P(zhao) ∨ P(li)         (3)与(4)归结

（13） P(sun) ∨﹁P(qian)         (3)与(5)归结

（14） P(qian)               (2)与(8)归结

（15） P(sun)               (2)与(13)归结

（16）NIL

所以，本题的盗窃犯是两个人：钱和孙。

同理可以证明，还可以是赵和孙、赵和钱


**4.过拟合和欠拟合是什么，产生过拟合原因以及对于决策树和神经网络怎么避免过拟合**

- 过拟合：模型在训练集上错误率很低，但是在未知数据上错误率很高。<br>
- 欠拟合：模型不能很好地拟合训练数据，在训练集和测试集上的错误率都比较高。<br>
- 过拟合的原因：过拟合问题往往是由于训练数据少和噪声以及模型复杂度过高等原因造成的。<br>
- 解决过拟合的方法：<br>
  1. 数据层面：增加训练数据、清除数据噪声<br>
  2. 模型层面：在经验风险最小化的基础上引入参数的正则化、模型训练提前迭代终止远侧、模型剪枝原则等。<br>
     例如，决策树模型可以通过先剪枝操作来控制决策树的生长或通过后剪枝操作对决策树进行修剪。神经网络模型可以通过加入L1正则化或者L2正则化、Dropout、early stopping等<br>



**5.关于机器学习算法评估，分别阐述适用于回归算法和分类算法的评估指标有哪些？并阐述各种评估指标的优缺点**


回归算法评估指标：

> a) 平均绝对误差（Mean Absolute Error）<br>
> b) 均方误差（Mean Squared Error）<br>
> c) 均方根误差（Root Mean Squared Error）<br>
> d) 决定系数（Coefficient of determination）<br>

分类算法评估指标：

> a) 精度 Accuracy<br>
> b) 混淆矩阵 Confusion Matrix<br>
> c) 准确率（查准率）Precision<br>
> d) 召回率（查全率）Recall<br>
> e) Fβ Score<br>
> f) AUC Area Under Curve<br>
> g) KS Kolmogorov-Smirnov<br>

回归算法评估指标的优缺点举例：

> a) MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致函数不光滑，在某些点上不能求导，可以考虑将绝对值改为残差的平方；<br>
> b) MSE与目标变量的量纲不一致；<br>
> c) RMSE可以保证量纲一致性；<br>
> d) 以上基于误差的均值对进行评估的指标，均值对异常点（outliers）较敏感，如果样本中有一些异常值出现，会对以上指标的值有较大影响。<br>

分类算法评估指标的优缺点举例：

> a) 对于有倾向性的问题，往往不能用精度指标来衡量。<br>
> b) 对于样本类别数量严重不均衡的情况，也不能用精度指标来衡量。<br>
> c) AUC是一种模型分类指标，且仅仅是二分类模型的评价指标。<br>
> d) AUC对样本类别是否均衡并不敏感；<br>



**6.决策树算法中，如何判断一个结点的最优划分属性是什么？当选序号作为最优划分属性时， 为什么基于信息增益的划分方法不再适用？**

1）通过计算属性集中每个属性的信息增益/增益率或基尼指数来判断

2）信息增益准则对可取值数目较多的属性有所偏好，通过增益率来判断可以有效防止该问题的出现



**7.集成算法中，除了Bagging算法以外，还有哪些算法？这些算法是如何将多个模型集成的？**

集成算法中包括Bagging算法、Boosting算法以及Stacking算法

2）Boosting算法：首先使用初始权重从训练集中训练出一个弱学习器，根据弱学习器的学习误差率来更新样本的权重，提高之前弱学习器误差率较高的训练样本点的权重，使得这些误差率高的样本在后面的弱学习器中得到更多的重视。如此循环，直到得到指定数量的学习器，再通过结合策略进行整合，得到最终的强学习器
1）Stacking算法：一种分层模型集成框架，通过训练集学习多个初级学习器，通过初级学习器对输入进行预测，
并将初级学习器的输出作为下一阶段的输入，用于训练次级学习器，以此类推直到最后一阶段输出到最终任务目标

